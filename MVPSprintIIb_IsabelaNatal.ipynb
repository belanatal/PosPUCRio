{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb",
      "authorship_tag": "ABX9TyNVf02I+DEtIycaH6SCgwIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PUC Rio: Pós Graduação em Ciência de Dados e Analytics**\n",
        "\n",
        "**MVP Sprint II: Machine Learning & Analytics (40530010056_20230_01)**\n",
        "**- Parte b**\n",
        "\n",
        "Aluna: Isabela Fernanda Natal Batista Abreu Gomes\n",
        "\n",
        "Julho/2023"
      ],
      "metadata": {
        "id": "NCmm_53qhu_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção I: Introdução\n",
        "**Classificador de imagens multiclasse - Paisagens Naturais**"
      ],
      "metadata": {
        "id": "f1C43RqyiAWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contexto:** O presente trabalho tem como objetivo criar um modelo de visão computacional baseado em Aprendizado de Máquina Profundo que seja capaz de classificar uma imagem segundo uma das 6 seguintes categorias de paisagens: Prédio; Floresta; Montanha; Geleira; Rua; Mar. Os dados/imagens foram baixados da plataforma Kaggle (Para mais informações \"Scene Classification\": https://www.kaggle.com/datasets/nitishabharathi/scene-classification).\n",
        "\n",
        "**Estrutura:** O notebook encontra-se dividido da seguinte forma:\n",
        "\n",
        "- Importação das bibliotecas\n",
        "- Acesso e tratamento dos dados que serão a entrada do modelo de deep learning\n",
        "- Configuração do modelo de deep learning usando uma rede neural convolucional simples com Keras\n",
        "- Treinamento do modelo de deep learning\n",
        "- Execução do modelo de deep learning treinado\n",
        "- Avaliação do modelo de deep learning\n",
        "- Exportação do modelo de deep learning\n",
        "- Teste do modelo exportado"
      ],
      "metadata": {
        "id": "byMSVk4ViRQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando as bibliotecas necessárias para executar o notebook\n",
        "(Serão utilizadas as bibliotecas pandas e numpy, para a manipulação dos dados; matplotlib, para geração de gráficos; os, para manipulação de pastas e diretórios e bibliotecas voltadas para Machine e Deep Learning, tais como Keras, Tensor Flow e Scikit-Learn)"
      ],
      "metadata": {
        "id": "eIgsgm4PvN4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "G-ym016rw-TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3baa330a-a8eb-4499-b3d7-8e965701524e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (16.0.0)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "YAPsYUGQu0x9",
        "outputId": "3dd788d4-109e-45da-b33a-02670aac5a23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro bloco: Importação das bibliotecas e módulos\n",
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#\n",
        "import os\n",
        "import cv2 # Visão computacional para análise em imagens\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn.metrics as skm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "#\n",
        "#Para utilizar o upload e download de arquivos no colab:\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "nYDd_EKHvzwV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wa4yvl2Du51E",
        "outputId": "afb5b679-5bc5-426c-f154-713feca9ecf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ftWobPBjv8Yb",
        "outputId": "48147787-aa7d-4d3f-d5aa-b4509474015e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Colab_Notebooks/Kaggle_API_Credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "eikc1A-MvpWJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download nitishabharathi/scene-classification"
      ],
      "metadata": {
        "id": "oTBqsxkVwQTJ",
        "outputId": "37606252-c95c-4d48-a684-9114b2450f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scene-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip scene-classification.zip"
      ],
      "metadata": {
        "id": "BJr0yxku4lmv",
        "outputId": "35dd8a49-1e7e-4a50-c464-9225b4ab72d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  scene-classification.zip\n",
            "replace test_WyRytb0.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/train-scene classification'):\n",
        "  os.rename('../content/train-scene classification','../content/scene')"
      ],
      "metadata": {
        "id": "zMLS6EtKN3C9",
        "outputId": "ea28b756-88a2-4d8f-d6ef-3003518e69cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-989a79d75bf1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/train-scene classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../content/train-scene classification'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'../content/scene'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: '../content/train-scene classification' -> '../content/scene'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/scene/train/*'):\n",
        "  os.rename('../content/scene/train/*','../content/scene/Imagens/*')"
      ],
      "metadata": {
        "id": "8C7bL45TOKT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino=pd.read_csv('../content/scene/train.csv',sep=',')\n",
        "teste=pd.read_csv('../content/test_WyRytb0.csv',sep=',')"
      ],
      "metadata": {
        "id": "seAs2zxs7iV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino.head()"
      ],
      "metadata": {
        "id": "1pv3Z6R--gm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando as dimensões dos DataFrames com as indicações das imagens correspondentes aos conjuntos de treino, teste\n",
        "print(treino.shape,teste.shape)"
      ],
      "metadata": {
        "id": "T7AVE_RypK-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se os DataFrames contêm dados nulos\n",
        "# Verify if the dataframe don't have NaN or null values\n",
        "check_for_nan_treino = treino.isnull().values.any()\n",
        "check_for_nan_teste = teste.isnull().values.any()\n",
        "\n",
        "print(check_for_nan_treino)\n",
        "print(check_for_nan_teste)"
      ],
      "metadata": {
        "id": "avrdjFoL84cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a lista para armazenar os dados e selecionar a pasta da imagem a ser carregada\n",
        "arquivos_com_label = []\n",
        "labels = []\n",
        "arquivos_teste = []\n",
        "imagePath = \"../content/scene/Imagens/\""
      ],
      "metadata": {
        "id": "ma89bt6e9dam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção II: Passos iniciais para tratamento dos dados"
      ],
      "metadata": {
        "id": "bDK8rZWKyV9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acessando e tratando os dados que serão a entrada do modelo de deep learning"
      ],
      "metadata": {
        "id": "X1RrUXN8xwdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o tamanho do batch e dimensão das imagens e a quantidade de épocas\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 6\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "X94GKPNHyi22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Associando as imagens ao dataset de treino\n",
        "for i in treino.index:\n",
        "    nameOfFile = treino['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        image = mpimg.imread(imagePath+nameOfFile)\n",
        "        if (len(image.shape)!=3): # Verify if the image is correct\n",
        "            print(\"A imagem N°\",i,' : ',nameOfFile,\" não está adequada\")\n",
        "        else :\n",
        "            image = cv2.resize(image,(img_width,img_height)) # conjunto de treino sem imagens \"expúrias\"\n",
        "            arquivos_com_label.append(image)\n",
        "            labels.append(treino['label'][i])\n",
        "print(len(arquivos_com_label))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "tLjPcA1oGWnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o dataset de treino em array\n",
        "arquivos_com_label = np.array(arquivos_com_label)\n",
        "labels = np.array(labels)\n",
        "print(arquivos_com_label.shape,labels.shape)"
      ],
      "metadata": {
        "id": "QCQV4JfFJc2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Associando as imagens ao dataset de teste\n",
        "# As imagens do dataset de teste contêm apenas o nome. Os labels (categorias de paisagem) serão preditos pelo modelo\n",
        "for i in teste.index:\n",
        "    nameOfFile = teste['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        image = mpimg.imread(imagePath+nameOfFile)\n",
        "        if (len(image.shape)!=3):\n",
        "            print(\"A imagem N°\",i,' : ',nameOfFile,\" não está adequada\")\n",
        "        else :\n",
        "            image = cv2.resize(image,(img_width,img_height)) # conjunto de teste sem imagens \"expúrias\"\n",
        "            arquivos_teste.append(image)\n",
        "print(len(arquivos_teste))"
      ],
      "metadata": {
        "id": "25jOXnsKJz7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o dataset de teste em array\n",
        "arquivos_teste = np.array(arquivos_teste)\n",
        "print(arquivos_teste.shape)"
      ],
      "metadata": {
        "id": "zjtczIikMDEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os caminhos de diretorios de treino, validação e teste\n",
        "train_dir = '/content/scene/treino'\n",
        "val_dir = '/content/scene/validacao'\n",
        "test_dir = '/content/scene/teste'\n",
        "treinamento_modelos_dir='/content/scene/trained_models'\n",
        "if not os.path.exists(train_dir):\n",
        "  os.makedirs(train_dir)\n",
        "if not os.path.exists(val_dir):\n",
        "  os.makedirs(val_dir)\n",
        "if not os.path.exists(test_dir):\n",
        "  os.makedirs(test_dir)\n",
        "if not os.path.exists(treinamento_modelos_dir):\n",
        "  os.makedirs(treinamento_modelos_dir)"
      ],
      "metadata": {
        "id": "huBaPDnzxiED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção III: Configuração do Modelo de Deep Learning"
      ],
      "metadata": {
        "id": "qcph1B6-9X1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do Modelo usando uma Rede Neural Convolucional (CNN) Simples"
      ],
      "metadata": {
        "id": "z0FWNskh9j9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando a biblioteca Keras, será especificada uma camada convolucional 2D com 32 filtros (depois 64, 128 e 256) e função de ativação do tipo ReLU. Na sequência é adicionada uma camada softmax com o mesmo tipo de função de ativação."
      ],
      "metadata": {
        "id": "00hhPnDH90yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 3, activation='relu', padding= \"same\", input_shape=(img_height,img_width,3)),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(128, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "87lAEFyo-avA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumindo o modelo que será utilizado\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HG_56PeAe-SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento do modelo de deep learning"
      ],
      "metadata": {
        "id": "Pk58X8Md-vkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos considerar o modelo Adam para otimização. Como métrica para avaliação do modelo, será usado o critério de acurácia. Além disso, por se tratar de um problema de classificação com mais de 2 categorias (6, neste problema), a perda considerada será do tipo entropia cruzada."
      ],
      "metadata": {
        "id": "fgvpuBNWWn1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fb3pY8mcX0D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação das imagens com labels fornecidos em treino e validação\n",
        "As imagens com categorias fornecidas conforme DataFrame treino serão divididas em treino de fato e validação"
      ],
      "metadata": {
        "id": "59hF9LJkfRC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos datasets de treino e validação (10% do conjunto original de treino, isto é, aproximadamente 1700 imagens serão separados para validação do modelo)\n",
        "X_train, X_val, y_train, y_val = train_test_split(arquivos_com_label,\n",
        "                                                    labels,\n",
        "                                                    test_size=0.10,\n",
        "                                                    train_size=0.90,\n",
        "                                                    random_state=7)"
      ],
      "metadata": {
        "id": "TrFB0er1f78c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando os comprimentos dos datasets de treino e validação\n",
        "print(X_train.shape,y_train.shape,X_val.shape,y_val.shape)\n",
        "print(X_train.dtype,y_train.dtype,X_val.dtype,y_val.dtype)\n",
        "# Alterando o tipo dos labels para inteiro (Lembrando que: 0-Edifício ; 1-Floresta; 2-Montanha; 3-Geleira; 4-Rua; 5-Mar)\n",
        "y_train = y_train.astype(np.uint8)\n",
        "y_val = y_val.astype(np.uint8)"
      ],
      "metadata": {
        "id": "W_23vDe6gXyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.dtype,y_train.dtype,X_val.dtype,y_val.dtype)"
      ],
      "metadata": {
        "id": "OHsgcfQNT8gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmando que os datasets possuem quantidades representativas de cada uma das seis categorias\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de treino:')\n",
        "print(dict(zip(unique, counts)))\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de validação:')\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "id": "sL2pRIN1435d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntrain = X_train.shape[0]\n",
        "nval = X_val.shape[0]"
      ],
      "metadata": {
        "id": "AKE7vjw6SXjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos dados\n",
        "Será utilizada a classe \"ImageDataGenerator\", do TensorFlow, destinada a aumentar e pré-processar dados de imagem em tarefas de Aprendizado Profundo."
      ],
      "metadata": {
        "id": "lZ4oq9ew0huC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "m-AYYjUZ_7Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos data generators\n",
        "train_generator = train_datagen.flow(X_train, y_train,batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "9IhUn2iWWrth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, steps_per_epoch=ntrain//batch_size,epochs=epochs, validation_data=val_generator,validation_steps=nval//batch_size)"
      ],
      "metadata": {
        "id": "J01IYgooX5sG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "42b940be-d347-4e9c-98db-576c84ccfb86"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-6f1e39e968bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnval\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção IV: Execução do Modelo de Deep Learning\n",
        "Nesta seção, o modelo treinado será aplicado em cada uma das imagens do dataset de teste, indicando a qual das 6 classes  (Edificio; Floresta; Montanha; Geleira; Rua; Mar) pertence."
      ],
      "metadata": {
        "id": "GcvXwPI1Zkir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dir = 'content/scene/test'\n",
        "count_images = 0\n",
        "class_names = ['Edificio',\n",
        "               'Floresta',\n",
        "               'Montanha',\n",
        "               'Geleira',\n",
        "               'Rua',\n",
        "               'Mar']\n",
        "y_pred = list()\n",
        "y_true = list()"
      ],
      "metadata": {
        "id": "enGyUduXlx2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorrendo a pasta onde estão salvas as imagens de teste (dividida em diretórios, subdiretórios e arquivos)\n",
        "\n",
        "for subdir, dirs, files in os.walk(parent_dir):\n",
        "  for file in files:\n",
        "    if file.endswith('.png') or file.endswith('.jpg'):  # Considerando que as imagens são de extensão .png ou .jpg\n",
        "#\n",
        "      count_images+=1\n",
        "      split_path = os.path.join(subdir, file).split('/')\n",
        "      label = split_path[3]\n",
        "      y_true.append(label)\n",
        "      img_path = os.path.join(subdir, file)\n",
        "      display(Image(filename=img_path, width=300))\n",
        "      img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "      figura = image.img_to_array(img)\n",
        "      figura = np.expand_dims(figura, axis=0)\n",
        "      figura = figura.astype('float32') / 255.0\n",
        "#\n",
        "      # Previsão\n",
        "      prediction = model.predict(figura)\n",
        "#\n",
        "      # Printando as saídas do modelo\n",
        "      predicted_class = np.argmax(prediction[0])\n",
        "      probability = prediction[0][predicted_class]\n",
        "      y_pred.append(class_names[predicted_class])\n",
        "      print(\"Categoria Real:\", label)\n",
        "      print(\"Categoria Prevista:\", class_names[predicted_class])\n",
        "      print(\"Probabilidade indicada para a categoria prevista:\", probability)\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "y9UKuUHSmCz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção V: Avaliação do Modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "nqocJPwRZrQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando as métricas para avaliação do modelo\n",
        "acuracia = skm.accuracy_score(y_true, y_pred)\n",
        "precisao = skm.precision_score(y_true, y_pred, average='weighted')\n",
        "recall = skm.recall_score(y_true, y_pred, average='weighted')\n",
        "f1score = skm.f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Acurácia: \", acuracia)\n",
        "print(\"Precisão: \", precisao)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F-Score: \", f1score)"
      ],
      "metadata": {
        "id": "9g7cZ1wSbAgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz de Confusão"
      ],
      "metadata": {
        "id": "ut1mEf41bsQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix = confusion_matrix(y_true, y_pred, labels=class_names)\n",
        "np.set_printoptions(precisao=2)\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      classes=['Edificio',\n",
        "                               'Floresta',\n",
        "                               'Montanha',\n",
        "                               'Geleira',\n",
        "                               'Rua',\n",
        "                               'Mar'],\n",
        "                      normalize= False,\n",
        "                      title='Matriz real x predição')"
      ],
      "metadata": {
        "id": "LlSvMncocspQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportação do Modelo"
      ],
      "metadata": {
        "id": "Em7aNXdOdTpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos salvar o modelo treinado para aplicação futura\n",
        "\n",
        "# obtendo a data e hora atual\n",
        "now = datetime.now()\n",
        "\n",
        "# Definição do formato\n",
        "format = '%Y-%m-%dT%H%M'\n",
        "\n",
        "# Converter a data e hora em uma string com o formato especificado\n",
        "formatted_datetime = now.strftime(format)\n",
        "\n",
        "path_model = 'content/scene/trained_models'\n",
        "\n",
        "name_model = 'trained_model_' + formatted_datetime + '.h5'\n",
        "\n",
        "# salvando o modelo\n",
        "model.save(\"%s/%s\" % (path_model, name_model))\n",
        "print(\"Modelo salvo com o nome: \", name_model)"
      ],
      "metadata": {
        "id": "WrwEB6TOdRgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}