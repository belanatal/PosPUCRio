{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOV3sO+Q9NTGyfa5fcO4iAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PUC Rio: Pós Graduação em Ciência de Dados e Analytics**\n",
        "\n",
        "**MVP Sprint II: Machine Learning & Analytics (40530010056_20230_01)**\n",
        "**- Parte b**\n",
        "\n",
        "Aluna: Isabela Fernanda Natal Batista Abreu Gomes\n",
        "\n",
        "Julho/2023"
      ],
      "metadata": {
        "id": "NCmm_53qhu_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção I: Introdução\n",
        "**Classificador de imagens multiclasse - Paisagens Naturais**"
      ],
      "metadata": {
        "id": "f1C43RqyiAWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contexto:** O presente trabalho tem como objetivo criar um modelo de visão computacional baseado em Aprendizado de Máquina Profundo que seja capaz de classificar uma imagem segundo uma das 6 seguintes categorias de paisagens: Prédio; Floresta; Montanha; Geleira; Rua; Mar. Os dados/imagens foram baixados da plataforma Kaggle (Para mais informações \"Scene Classification\": https://www.kaggle.com/datasets/nitishabharathi/scene-classification).\n",
        "\n",
        "**Estrutura:** O notebook encontra-se dividido da seguinte forma:\n",
        "\n",
        "- Importação das bibliotecas\n",
        "- Acesso e tratamento dos dados que serão a entrada do modelo de deep learning\n",
        "- Configuração do modelo de deep learning usando uma rede neural convolucional simples com Keras\n",
        "- Treinamento do modelo de deep learning\n",
        "- Execução do modelo de deep learning treinado\n",
        "- Avaliação do modelo de deep learning\n",
        "- Exportação do modelo de deep learning\n",
        "- Teste do modelo exportado"
      ],
      "metadata": {
        "id": "byMSVk4ViRQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando as bibliotecas necessárias para executar o notebook\n",
        "(Serão utilizadas as bibliotecas pandas e numpy, para a manipulação dos dados; matplotlib, para geração de gráficos; os, para manipulação de pastas e diretórios e bibliotecas voltadas para Machine e Deep Learning, tais como Keras, Tensor Flow e Scikit-Learn)"
      ],
      "metadata": {
        "id": "eIgsgm4PvN4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "G-ym016rw-TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro bloco: Importação das bibliotecas e módulos\n",
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn.metrics as skm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nYDd_EKHvzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção II: Passos iniciais para tratamento dos dados"
      ],
      "metadata": {
        "id": "bDK8rZWKyV9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acessando e tratando os dados que serão a entrada do modelo de deep learning"
      ],
      "metadata": {
        "id": "X1RrUXN8xwdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os caminhos dos diretórios para os dados de treinamento, teste e validação\n",
        "train_dir = 'datasets/scene/train'\n",
        "val_dir = 'datasets/scene/val'\n",
        "test_dir = 'datasets/scene/test'"
      ],
      "metadata": {
        "id": "huBaPDnzxiED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o tamanho do batch e dimensão das imagens\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 6"
      ],
      "metadata": {
        "id": "X94GKPNHyi22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos dados\n",
        "Será utilizada a classe \"ImageDataGenerator\", do TensorFlow, destinada a aumentar e pré-processar dados de imagem em tarefas de Aprendizado Profundo."
      ],
      "metadata": {
        "id": "lZ4oq9ew0huC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Criação dos data generators\n",
        "# Para o subconjunto de treino\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(img_height, img_width),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical') #training set\n",
        "# Para o subconjunto de validação\n",
        "val_generator = test_datagen.flow_from_directory(val_dir,\n",
        "                                                target_size=(img_height, img_width),\n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical')\n",
        "# Para o subconjunto de teste\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                target_size=(img_height, img_width),\n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical')"
      ],
      "metadata": {
        "id": "t4w5Gn0F0pY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção III: Configuração do Modelo de Deep Learning"
      ],
      "metadata": {
        "id": "qcph1B6-9X1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do Modelo usando uma Rede Neural Convolucional (CNN) Simples"
      ],
      "metadata": {
        "id": "z0FWNskh9j9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando a biblioteca Keras, será especificada uma camada convolucional 2D com 32 filtros (depois 64 e 128) e função de ativação do tipo ReLU. Na sequência é adicionada uma camada softmax com o mesmo tipo de função de ativação."
      ],
      "metadata": {
        "id": "00hhPnDH90yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_height,img_width,3)),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "87lAEFyo-avA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento do modelo de deep learning"
      ],
      "metadata": {
        "id": "Pk58X8Md-vkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos considerar o modelo Adam para otimização. Como métrica para avaliação do modelo, será usado o critério de acurácia. Além disso, por se tratar de um problema de classificação com mais de 2 categorias (6, neste problema), a perda considerada será do tipo entropia cruzada."
      ],
      "metadata": {
        "id": "fgvpuBNWWn1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fb3pY8mcX0D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a quantidade de épocas de treinamento do modelo\n",
        "epochs = 50\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)"
      ],
      "metadata": {
        "id": "J01IYgooX5sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção IV: Execução do Modelo de Deep Learning\n",
        "Nesta seção, o modelo treinado será aplicado em cada uma das imagens do dataset de teste, indicando a qual das 6 classes  (Prédio; Floresta; Montanha; Geleira; Rua; Mar) pertence."
      ],
      "metadata": {
        "id": "GcvXwPI1Zkir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dir = 'datasets/scene/test'\n",
        "count_images = 0\n",
        "class_names = ['Predio',\n",
        "               'Floresta',\n",
        "               'Montanha',\n",
        "               'Geleira',\n",
        "               'Rua',\n",
        "               'Mar']\n",
        "y_pred = list()\n",
        "y_true = list()"
      ],
      "metadata": {
        "id": "enGyUduXlx2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorrendo a pasta onde estão salvas as imagens de teste (dividida em diretórios, subdiretórios e arquivos)\n",
        "\n",
        "for subdir, dirs, files in os.walk(parent_dir):\n",
        "  for file in files:\n",
        "    if file.endswith('.png') or file.endswith('.jpg'):  # Considerando que as imagens são de extensão .png ou .jpg\n",
        "#\n",
        "      count_images+=1\n",
        "      split_path = os.path.join(subdir, file).split('/')\n",
        "      label = split_path[3]\n",
        "      y_true.append(label)\n",
        "      img_path = os.path.join(subdir, file)\n",
        "      display(Image(filename=img_path, width=300))\n",
        "      img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "      figura = image.img_to_array(img)\n",
        "      figura = np.expand_dims(figura, axis=0)\n",
        "      figura = figura.astype('float32') / 255.0\n",
        "#\n",
        "      # Previsão\n",
        "      prediction = model.predict(figura)\n",
        "#\n",
        "      # Printando as saídas do modelo\n",
        "      predicted_class = np.argmax(prediction[0])\n",
        "      probability = prediction[0][predicted_class]\n",
        "      y_pred.append(class_names[predicted_class])\n",
        "      print(\"Categoria Real:\", label)\n",
        "      print(\"Categoria Prevista:\", class_names[predicted_class])\n",
        "      print(\"Probabilidade indicada para a categoria prevista:\", probability)\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "y9UKuUHSmCz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nqocJPwRZrQm"
      }
    }
  ]
}