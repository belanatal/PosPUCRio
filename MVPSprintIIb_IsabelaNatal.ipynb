{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb",
      "authorship_tag": "ABX9TyNAZSFJW8Va1IQaI1AuF+GB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PUC Rio: Pós Graduação em Ciência de Dados e Analytics**\n",
        "\n",
        "**MVP Sprint II: Machine Learning & Analytics (40530010056_20230_01)**\n",
        "**- Parte b**\n",
        "\n",
        "Aluna: Isabela Fernanda Natal Batista Abreu Gomes\n",
        "\n",
        "Julho/2023"
      ],
      "metadata": {
        "id": "NCmm_53qhu_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção I: Introdução\n",
        "**Classificador de imagens multiclasse - Paisagens Naturais**"
      ],
      "metadata": {
        "id": "f1C43RqyiAWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contexto:** O presente trabalho tem como objetivo criar um modelo de visão computacional baseado em Aprendizado de Máquina Profundo que seja capaz de classificar uma imagem segundo uma das 6 seguintes categorias de paisagens: Prédio; Floresta; Montanha; Geleira; Rua; Mar. Os dados/imagens foram baixados da plataforma Kaggle (Para mais informações \"Scene Classification\": https://www.kaggle.com/datasets/nitishabharathi/scene-classification).\n",
        "\n",
        "**Estrutura:** O notebook encontra-se dividido da seguinte forma:\n",
        "\n",
        "- Importação das bibliotecas\n",
        "- Acesso e tratamento dos dados que serão a entrada do modelo de deep learning\n",
        "- Configuração do modelo de deep learning usando uma rede neural convolucional simples com Keras\n",
        "- Treinamento do modelo de deep learning\n",
        "- Execução do modelo de deep learning treinado\n",
        "- Avaliação do modelo de deep learning\n",
        "- Exportação do modelo de deep learning\n",
        "- Teste do modelo exportado"
      ],
      "metadata": {
        "id": "byMSVk4ViRQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando as bibliotecas necessárias para executar o notebook\n",
        "(Serão utilizadas as bibliotecas pandas e numpy, para a manipulação dos dados; matplotlib, para geração de gráficos; os, para manipulação de pastas e diretórios e bibliotecas voltadas para Machine e Deep Learning, tais como Keras, Tensor Flow e Scikit-Learn)"
      ],
      "metadata": {
        "id": "eIgsgm4PvN4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "G-ym016rw-TY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3baa330a-a8eb-4499-b3d7-8e965701524e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.13 in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.8.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (16.0.0)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "YAPsYUGQu0x9",
        "outputId": "3dd788d4-109e-45da-b33a-02670aac5a23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro bloco: Importação das bibliotecas e módulos\n",
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#\n",
        "import os\n",
        "import cv2 # Visão computacional para análise em imagens\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn.metrics as skm\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "#\n",
        "#Para utilizar o upload e download de arquivos no colab:\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "nYDd_EKHvzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wa4yvl2Du51E",
        "outputId": "afb5b679-5bc5-426c-f154-713feca9ecf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ftWobPBjv8Yb",
        "outputId": "48147787-aa7d-4d3f-d5aa-b4509474015e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Colab_Notebooks/Kaggle_API_Credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "eikc1A-MvpWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download nitishabharathi/scene-classification"
      ],
      "metadata": {
        "id": "oTBqsxkVwQTJ",
        "outputId": "37606252-c95c-4d48-a684-9114b2450f90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scene-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip scene-classification.zip"
      ],
      "metadata": {
        "id": "BJr0yxku4lmv",
        "outputId": "35dd8a49-1e7e-4a50-c464-9225b4ab72d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  scene-classification.zip\n",
            "replace test_WyRytb0.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/train-scene classification'):\n",
        "  os.rename('../content/train-scene classification','../content/scene')"
      ],
      "metadata": {
        "id": "zMLS6EtKN3C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/scene/train/*'):\n",
        "  os.rename('../content/scene/train/*','../content/scene/Imagens/*')"
      ],
      "metadata": {
        "id": "8C7bL45TOKT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino=pd.read_csv('../content/scene/train.csv',sep=',')\n",
        "teste=pd.read_csv('../content/test_WyRytb0.csv',sep=',')"
      ],
      "metadata": {
        "id": "seAs2zxs7iV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino.head()"
      ],
      "metadata": {
        "id": "1pv3Z6R--gm6",
        "outputId": "74800c09-91b5-411d-8be7-356834071c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  image_name  label\n",
              "0      0.jpg      0\n",
              "1      1.jpg      4\n",
              "2      2.jpg      5\n",
              "3      4.jpg      0\n",
              "4      7.jpg      4"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-bbb6cf54-6d95-4f33-af4e-6b6bcd552523\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbb6cf54-6d95-4f33-af4e-6b6bcd552523')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a43f51f5-d945-410f-b45c-8d0e05a22980\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a43f51f5-d945-410f-b45c-8d0e05a22980')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a43f51f5-d945-410f-b45c-8d0e05a22980 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbb6cf54-6d95-4f33-af4e-6b6bcd552523 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbb6cf54-6d95-4f33-af4e-6b6bcd552523');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando as dimensões dos DataFrames com as indicações das imagens correspondentes aos conjuntos de treino, teste\n",
        "print(treino.shape,teste.shape)"
      ],
      "metadata": {
        "id": "T7AVE_RypK-C",
        "outputId": "440ca62b-7a56-4d02-8eb5-fd7d7f5ac8b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17034, 2) (7301, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se os DataFrames contêm dados nulos\n",
        "# Verify if the dataframe don't have NaN or null values\n",
        "check_for_nan_treino = treino.isnull().values.any()\n",
        "check_for_nan_teste = teste.isnull().values.any()\n",
        "\n",
        "print(check_for_nan_treino)\n",
        "print(check_for_nan_teste)"
      ],
      "metadata": {
        "id": "avrdjFoL84cE",
        "outputId": "ab7bd9c3-597e-450d-ee75-5e824b2c2ee1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a lista para armazenar os dados e selecionar a pasta da imagem a ser carregada\n",
        "arquivos_com_label = []\n",
        "labels = []\n",
        "arquivos_teste = []\n",
        "arquivos_teste_prediction = []\n",
        "imagePath = \"../content/scene/Imagens/\""
      ],
      "metadata": {
        "id": "ma89bt6e9dam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção II: Passos iniciais para tratamento dos dados"
      ],
      "metadata": {
        "id": "bDK8rZWKyV9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acessando e tratando os dados que serão a entrada do modelo de deep learning"
      ],
      "metadata": {
        "id": "X1RrUXN8xwdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o tamanho do batch e dimensão das imagens e a quantidade de épocas\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 6\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "X94GKPNHyi22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Associando as imagens ao dataset de treino\n",
        "for i in treino.index:\n",
        "    nameOfFile = treino['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        image = mpimg.imread(imagePath+nameOfFile)\n",
        "        if (len(image.shape)!=3): # Verify if the image is correct\n",
        "            print(\"A imagem N°\",i,' : ',nameOfFile,\" não está adequada\")\n",
        "        else :\n",
        "            image = cv2.resize(image,(img_width,img_height)) # conjunto de treino sem imagens \"expúrias\"\n",
        "            arquivos_com_label.append(image)\n",
        "            labels.append(treino['label'][i])\n",
        "print(len(arquivos_com_label))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "tLjPcA1oGWnr",
        "outputId": "f94c61c5-9af3-4e39-8852-6f6ac05f561e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17034\n",
            "17034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o dataset de treino em array\n",
        "arquivos_com_label = np.array(arquivos_com_label)\n",
        "labels = np.array(labels)\n",
        "print(arquivos_com_label.shape,labels.shape)"
      ],
      "metadata": {
        "id": "QCQV4JfFJc2V",
        "outputId": "e55c2376-209e-475e-f14c-579996a06c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17034, 224, 224, 3) (17034,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Associando as imagens ao dataset de teste\n",
        "# As imagens do dataset de teste contêm apenas o nome. Os labels (categorias de paisagem) serão preditos pelo modelo\n",
        "for i in teste.index:\n",
        "    nameOfFile = teste['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        image_teste = mpimg.imread(imagePath+nameOfFile)\n",
        "        if (len(image.shape)!=3):\n",
        "            print(\"A imagem N°\",i,' : ',nameOfFile,\" não está adequada\")\n",
        "        else :\n",
        "            image_teste = cv2.resize(image_teste,(img_width,img_height)) # conjunto de teste sem imagens \"expúrias\"\n",
        "            arquivos_teste.append(image_teste)\n",
        "print(len(arquivos_teste))"
      ],
      "metadata": {
        "id": "25jOXnsKJz7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb7fffe6-73e4-46c5-d02f-a8eb1664a0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A imagem N° 2280  :  7606.jpg  não está adequada\n",
            "7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o dataset de teste em array\n",
        "arquivos_teste = np.array(arquivos_teste)\n",
        "print(arquivos_teste.shape)"
      ],
      "metadata": {
        "id": "zjtczIikMDEf",
        "outputId": "9c02d442-e755-49ac-a7f4-29b4fcbb3abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7300, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os caminhos de diretorios de treino, validação e teste\n",
        "train_dir = '/content/scene/treino'\n",
        "val_dir = '/content/scene/validacao'\n",
        "test_dir = '/content/scene/teste'\n",
        "treinamento_modelos_dir='/content/scene/trained_models'\n",
        "if not os.path.exists(train_dir):\n",
        "  os.makedirs(train_dir)\n",
        "if not os.path.exists(val_dir):\n",
        "  os.makedirs(val_dir)\n",
        "if not os.path.exists(test_dir):\n",
        "  os.makedirs(test_dir)\n",
        "if not os.path.exists(treinamento_modelos_dir):\n",
        "  os.makedirs(treinamento_modelos_dir)"
      ],
      "metadata": {
        "id": "huBaPDnzxiED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção III: Configuração do Modelo de Deep Learning"
      ],
      "metadata": {
        "id": "qcph1B6-9X1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do Modelo usando uma Rede Neural Convolucional (CNN) Simples"
      ],
      "metadata": {
        "id": "z0FWNskh9j9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando a biblioteca Keras, será especificada uma camada convolucional 2D com 32 filtros (depois 64, 128 e 256) e função de ativação do tipo ReLU. Na sequência é adicionada uma camada softmax com o mesmo tipo de função de ativação."
      ],
      "metadata": {
        "id": "00hhPnDH90yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 3, activation='relu', padding= \"same\", input_shape=(img_height,img_width,3)),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(128, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "87lAEFyo-avA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumindo o modelo que será utilizado\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HG_56PeAe-SD",
        "outputId": "7d03bc6a-cf9f-4bf9-c187-005301da0c66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               12845184  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20452166 (78.02 MB)\n",
            "Trainable params: 20452166 (78.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento do modelo de deep learning"
      ],
      "metadata": {
        "id": "Pk58X8Md-vkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos considerar o modelo Adam para otimização. Como métrica para avaliação do modelo, será usado o critério de acurácia. Além disso, por se tratar de um problema de classificação com mais de 2 categorias (6, neste problema), a perda considerada será do tipo entropia cruzada."
      ],
      "metadata": {
        "id": "fgvpuBNWWn1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fb3pY8mcX0D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação das imagens com labels fornecidos em treino e validação\n",
        "As imagens com categorias fornecidas conforme DataFrame treino serão divididas em treino de fato e validação"
      ],
      "metadata": {
        "id": "59hF9LJkfRC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos datasets de treino e validação (10% do conjunto original de treino, isto é, aproximadamente 1700 imagens serão separados para validação do modelo)\n",
        "X_train, X_val, y_train, y_val = train_test_split(arquivos_com_label,\n",
        "                                                    labels,\n",
        "                                                    test_size=0.10,\n",
        "                                                    train_size=0.90,\n",
        "                                                    random_state=7)"
      ],
      "metadata": {
        "id": "TrFB0er1f78c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando os comprimentos dos datasets de treino e validação\n",
        "print(X_train.shape,y_train.shape,X_val.shape,y_val.shape)\n",
        "print(X_train.dtype,y_train.dtype,X_val.dtype,y_val.dtype)\n",
        "# Alterando o tipo dos labels para inteiro (Lembrando que: 0-Edifício ; 1-Floresta; 2-Montanha; 3-Geleira; 4-Rua; 5-Mar)\n",
        "y_train = y_train.astype(np.uint8)\n",
        "y_val = y_val.astype(np.uint8)"
      ],
      "metadata": {
        "id": "W_23vDe6gXyB",
        "outputId": "a5dbfff4-e8a6-4370-991c-eeb0d71271bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15330, 224, 224, 3) (15330,) (1704, 224, 224, 3) (1704,)\n",
            "uint8 int64 uint8 int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.dtype,y_train.dtype,X_val.dtype,y_val.dtype)"
      ],
      "metadata": {
        "id": "OHsgcfQNT8gW",
        "outputId": "62b366e1-63bd-4621-99fd-f085f2ff64f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uint8 uint8 uint8 uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmando que os datasets possuem quantidades representativas de cada uma das seis categorias\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de treino:')\n",
        "print(dict(zip(unique, counts)))\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de validação:')\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "id": "sL2pRIN1435d",
        "outputId": "d36f7d43-7d42-49d6-e13c-a3212ac291fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuição quantitativa dos labels no dataset de treino:\n",
            "{0: 2343, 1: 2498, 2: 2650, 3: 2732, 4: 2506, 5: 2601}\n",
            "Distribuição quantitativa dos labels no dataset de validação:\n",
            "{0: 285, 1: 247, 2: 307, 3: 305, 4: 278, 5: 282}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliar em 21/07"
      ],
      "metadata": {
        "id": "vsruhAjKwKFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando algumas imagens do conjunto de treino\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(3*4, 3*4)\n",
        "\n",
        "# Visualizando apenas 12 imagens que têm categoria associada\n",
        "for i in range(12):\n",
        "\n",
        "    sample = np.random.choice(arquivos_com_label)\n",
        "    sp = plt.subplot(3, 4, i + 1)\n",
        "    sp.axis('Off')\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(sample[:3])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XiIr0UVHvMl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntrain = X_train.shape[0]\n",
        "nval = X_val.shape[0]"
      ],
      "metadata": {
        "id": "AKE7vjw6SXjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos dados\n",
        "Será utilizada a classe \"ImageDataGenerator\", do TensorFlow, destinada a aumentar e pré-processar dados de imagem em tarefas de Aprendizado Profundo."
      ],
      "metadata": {
        "id": "lZ4oq9ew0huC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "m-AYYjUZ_7Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação dos data generators\n",
        "train_generator = train_datagen.flow(X_train, y_train,batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "9IhUn2iWWrth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, steps_per_epoch=ntrain//batch_size,epochs=epochs, validation_data=val_generator,validation_steps=nval//batch_size)"
      ],
      "metadata": {
        "id": "J01IYgooX5sG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c82fe619-ea45-495c-bf0e-51e04c0623ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "479/479 [==============================] - 200s 370ms/step - loss: 1.6808 - accuracy: 0.2873 - val_loss: 1.4298 - val_accuracy: 0.4163\n",
            "Epoch 2/30\n",
            "479/479 [==============================] - 181s 377ms/step - loss: 1.4615 - accuracy: 0.4046 - val_loss: 1.2525 - val_accuracy: 0.5371\n",
            "Epoch 3/30\n",
            "479/479 [==============================] - 180s 374ms/step - loss: 1.3341 - accuracy: 0.4690 - val_loss: 1.1244 - val_accuracy: 0.6020\n",
            "Epoch 4/30\n",
            "479/479 [==============================] - 177s 368ms/step - loss: 1.2415 - accuracy: 0.5149 - val_loss: 0.9512 - val_accuracy: 0.6680\n",
            "Epoch 5/30\n",
            "479/479 [==============================] - 179s 373ms/step - loss: 1.1421 - accuracy: 0.5553 - val_loss: 0.8252 - val_accuracy: 0.7134\n",
            "Epoch 6/30\n",
            "479/479 [==============================] - 179s 373ms/step - loss: 1.0795 - accuracy: 0.5906 - val_loss: 0.8618 - val_accuracy: 0.6798\n",
            "Epoch 7/30\n",
            "479/479 [==============================] - 181s 378ms/step - loss: 1.0005 - accuracy: 0.6291 - val_loss: 0.7383 - val_accuracy: 0.7276\n",
            "Epoch 8/30\n",
            "479/479 [==============================] - 186s 387ms/step - loss: 0.9408 - accuracy: 0.6611 - val_loss: 0.7093 - val_accuracy: 0.7500\n",
            "Epoch 9/30\n",
            "479/479 [==============================] - 185s 385ms/step - loss: 0.8850 - accuracy: 0.6883 - val_loss: 0.7528 - val_accuracy: 0.7199\n",
            "Epoch 10/30\n",
            "479/479 [==============================] - 182s 379ms/step - loss: 0.8412 - accuracy: 0.7073 - val_loss: 0.6279 - val_accuracy: 0.7665\n",
            "Epoch 11/30\n",
            "479/479 [==============================] - 178s 372ms/step - loss: 0.7991 - accuracy: 0.7251 - val_loss: 0.6191 - val_accuracy: 0.7848\n",
            "Epoch 12/30\n",
            "166/479 [=========>....................] - ETA: 1:54 - loss: 0.7635 - accuracy: 0.7395"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção IV: Execução do Modelo de Deep Learning\n",
        "Nesta seção, o modelo treinado será aplicado em cada uma das imagens do dataset de teste, indicando a qual das 6 classes  (Edificio; Floresta; Montanha; Geleira; Rua; Mar) pertence."
      ],
      "metadata": {
        "id": "GcvXwPI1Zkir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CONTINUAR DAQUI EM 21/07"
      ],
      "metadata": {
        "id": "PgiPP7lPrCOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dir = '../content/scene/teste'\n",
        "count_images = 0\n",
        "class_names = ['Edificio',\n",
        "               'Floresta',\n",
        "               'Montanha',\n",
        "               'Geleira',\n",
        "               'Rua',\n",
        "               'Mar']\n",
        "y_pred = list()\n",
        "y_true = list()"
      ],
      "metadata": {
        "id": "enGyUduXlx2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Associando as imagens ao dataset de teste\n",
        "# As imagens do dataset de teste contêm apenas o nome. Os labels (categorias de paisagem) serão preditos pelo modelo\n",
        "for i in teste.index:\n",
        "    nameOfFile = teste['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        image = mpimg.imread(imagePath+nameOfFile)\n",
        "        if (len(image.shape)!=3):\n",
        "            print(\"A imagem N°\",i,' : ',nameOfFile,\" não está adequada\")\n",
        "        else :\n",
        "            image = cv2.resize(image,(img_width,img_height)) # conjunto de teste sem imagens \"expúrias\"\n",
        "            # Previsão\n",
        "            prediction = model.predict(image)\n",
        "            arquivos_teste_prediction.append(prediction)\n",
        "            arquivos_teste.append(image)\n",
        "print(len(arquivos_teste))\n",
        "print(len(arquivos_teste_prediction))"
      ],
      "metadata": {
        "id": "wGg-3w4GmrUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorrendo a pasta onde estão salvas as imagens de teste (dividida em diretórios, subdiretórios e arquivos)\n",
        "\n",
        "for subdir, dirs, files in os.walk(parent_dir):\n",
        "  for file in files:\n",
        "    if file.endswith('.png') or file.endswith('.jpg'):  # Considerando que as imagens são de extensão .png ou .jpg\n",
        "#\n",
        "      count_images+=1\n",
        "      split_path = os.path.join(subdir, file).split('/')\n",
        "      label = split_path[3]\n",
        "      y_true.append(label)\n",
        "      img_path = os.path.join(subdir, file)\n",
        "      display(Image(filename=img_path, width=300))\n",
        "      img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "      figura = image.img_to_array(img)\n",
        "      figura = np.expand_dims(figura, axis=0)\n",
        "      figura = figura.astype('float32') / 255.0\n",
        "#\n",
        "      # Previsão\n",
        "      prediction = model.predict(figura)\n",
        "#\n",
        "      # Printando as saídas do modelo\n",
        "      predicted_class = np.argmax(prediction[0])\n",
        "      probability = prediction[0][predicted_class]\n",
        "      y_pred.append(class_names[predicted_class])\n",
        "      print(\"Categoria Real:\", label)\n",
        "      print(\"Categoria Prevista:\", class_names[predicted_class])\n",
        "      print(\"Probabilidade indicada para a categoria prevista:\", probability)\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "y9UKuUHSmCz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção V: Avaliação do Modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "nqocJPwRZrQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando as métricas para avaliação do modelo\n",
        "acuracia = skm.accuracy_score(y_true, y_pred)\n",
        "precisao = skm.precision_score(y_true, y_pred, average='weighted')\n",
        "recall = skm.recall_score(y_true, y_pred, average='weighted')\n",
        "f1score = skm.f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Acurácia: \", acuracia)\n",
        "print(\"Precisão: \", precisao)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F-Score: \", f1score)"
      ],
      "metadata": {
        "id": "9g7cZ1wSbAgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz de Confusão"
      ],
      "metadata": {
        "id": "ut1mEf41bsQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix = confusion_matrix(y_true, y_pred, labels=class_names)\n",
        "np.set_printoptions(precisao=2)\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      classes=['Edificio',\n",
        "                               'Floresta',\n",
        "                               'Montanha',\n",
        "                               'Geleira',\n",
        "                               'Rua',\n",
        "                               'Mar'],\n",
        "                      normalize= False,\n",
        "                      title='Matriz real x predição')"
      ],
      "metadata": {
        "id": "LlSvMncocspQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportação do Modelo"
      ],
      "metadata": {
        "id": "Em7aNXdOdTpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos salvar o modelo treinado para aplicação futura\n",
        "\n",
        "# obtendo a data e hora atual\n",
        "now = datetime.now()\n",
        "\n",
        "# Definição do formato\n",
        "format = '%Y-%m-%dT%H%M'\n",
        "\n",
        "# Converter a data e hora em uma string com o formato especificado\n",
        "formatted_datetime = now.strftime(format)\n",
        "\n",
        "path_model = treinamento_modelos_dir\n",
        "\n",
        "name_model = 'trained_model_' + formatted_datetime + '.h5'\n",
        "\n",
        "# salvando o modelo\n",
        "model.save(\"%s/%s\" % (path_model, name_model))\n",
        "print(\"Modelo salvo com o nome: \", name_model)"
      ],
      "metadata": {
        "id": "WrwEB6TOdRgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}