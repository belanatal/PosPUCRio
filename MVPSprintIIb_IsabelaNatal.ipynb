{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9wvYpEDOIFcR6zzaXrWTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PUC Rio: Pós Graduação em Ciência de Dados e Analytics**\n",
        "\n",
        "**MVP Sprint II: Machine Learning & Analytics (40530010056_20230_01)**\n",
        "**- Parte b**\n",
        "\n",
        "Aluna: Isabela Fernanda Natal Batista Abreu Gomes\n",
        "\n",
        "Julho/2023"
      ],
      "metadata": {
        "id": "NCmm_53qhu_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção I: Introdução\n",
        "**Classificador de imagens multiclasse - Paisagens Naturais**"
      ],
      "metadata": {
        "id": "f1C43RqyiAWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contexto:** O presente trabalho tem como objetivo criar um modelo de visão computacional baseado em Aprendizado de Máquina Profundo que seja capaz de classificar uma imagem segundo uma das 6 seguintes categorias de paisagens: Prédio; Floresta; Montanha; Geleira; Rua; Mar. Os dados/imagens foram baixados da plataforma Kaggle (Para mais informações \"Scene Classification\": https://www.kaggle.com/datasets/nitishabharathi/scene-classification).\n",
        "\n",
        "**Estrutura:** O notebook encontra-se dividido da seguinte forma:\n",
        "\n",
        "- Importação das bibliotecas\n",
        "- Acesso e tratamento dos dados que serão a entrada do modelo de deep learning\n",
        "- Configuração do modelo de deep learning usando uma rede neural convolucional simples com Keras\n",
        "- Treinamento do modelo de deep learning\n",
        "- Execução do modelo de deep learning treinado\n",
        "- Avaliação do modelo de deep learning\n",
        "- Exportação do modelo de deep learning\n",
        "- Teste do modelo exportado"
      ],
      "metadata": {
        "id": "byMSVk4ViRQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando as bibliotecas necessárias para executar o notebook\n",
        "(Serão utilizadas as bibliotecas pandas e numpy, para a manipulação dos dados; matplotlib, para geração de gráficos; os, para manipulação de pastas e diretórios e bibliotecas voltadas para Machine e Deep Learning, tais como Keras, Tensor Flow e Scikit-Learn)"
      ],
      "metadata": {
        "id": "eIgsgm4PvN4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "G-ym016rw-TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro bloco: Importação das bibliotecas e módulos\n",
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn.metrics as skm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nYDd_EKHvzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção II: Passos iniciais para tratamento dos dados"
      ],
      "metadata": {
        "id": "bDK8rZWKyV9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acessando e tratando os dados que serão a entrada do modelo de deep learning"
      ],
      "metadata": {
        "id": "X1RrUXN8xwdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os caminhos dos diretórios para os dados de treinamento, teste e validação\n",
        "train_dir = 'datasets/scene/train'\n",
        "val_dir = 'datasets/scene/val'\n",
        "test_dir = 'datasets/scene/test'"
      ],
      "metadata": {
        "id": "huBaPDnzxiED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o tamanho do batch e dimensão das imagens\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 6"
      ],
      "metadata": {
        "id": "X94GKPNHyi22"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}