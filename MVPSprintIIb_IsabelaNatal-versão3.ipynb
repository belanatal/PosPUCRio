{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal.ipynb",
      "authorship_tag": "ABX9TyNMrxa23BIjDzgrXIWocsS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belanatal/PosPUCRio/blob/main/MVPSprintIIb_IsabelaNatal-vers%C3%A3o3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PUC Rio: Pós Graduação em Ciência de Dados e Analytics**\n",
        "\n",
        "**MVP Sprint II: Machine Learning & Analytics (40530010056_20230_01)**\n",
        "**- Parte b**\n",
        "\n",
        "Aluna: Isabela Fernanda Natal Batista Abreu Gomes\n",
        "\n",
        "Julho/2023"
      ],
      "metadata": {
        "id": "NCmm_53qhu_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção I: Introdução\n",
        "**Classificador de imagens multiclasse - Paisagens Naturais**"
      ],
      "metadata": {
        "id": "f1C43RqyiAWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contexto:** O presente trabalho tem como objetivo criar um modelo de visão computacional baseado em Aprendizado de Máquina Profundo que seja capaz de classificar uma imagem segundo uma das 6 seguintes categorias de paisagens: Prédio; Floresta; Montanha; Geleira; Rua; Mar. Os dados/imagens foram baixados da plataforma Kaggle (Para mais informações \"Scene Classification\": https://www.kaggle.com/datasets/nitishabharathi/scene-classification).\n",
        "\n",
        "**Estrutura:** O notebook encontra-se dividido da seguinte forma:\n",
        "\n",
        "- Importação das bibliotecas\n",
        "- Acesso e tratamento dos dados que serão a entrada do modelo de deep learning\n",
        "- Configuração do modelo de deep learning usando uma rede neural convolucional simples com Keras\n",
        "- Treinamento do modelo de deep learning\n",
        "- Execução do modelo de deep learning treinado\n",
        "- Avaliação do modelo de deep learning\n",
        "- Exportação do modelo de deep learning\n",
        "- Teste do modelo exportado"
      ],
      "metadata": {
        "id": "byMSVk4ViRQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando as bibliotecas necessárias para executar o notebook\n",
        "(Serão utilizadas as bibliotecas pandas e numpy, para a manipulação dos dados; matplotlib, para geração de gráficos; os, para manipulação de pastas e diretórios e bibliotecas voltadas para Machine e Deep Learning, tais como Keras, Tensor Flow e Scikit-Learn)"
      ],
      "metadata": {
        "id": "eIgsgm4PvN4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "G-ym016rw-TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro bloco: Importação das bibliotecas e módulos\n",
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#\n",
        "import os\n",
        "import cv2 # Visão computacional para análise em imagens\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn.metrics as skm\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "#\n",
        "#Para utilizar o upload e download de arquivos no colab:\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import gdown\n",
        "from zipfile import ZipFile"
      ],
      "metadata": {
        "id": "nYDd_EKHvzwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definindo a função plot_confusion_matrix\n",
        "Para impressão da matriz de confusão na etapa de avaliação do método"
      ],
      "metadata": {
        "id": "XhYlvvXDlEBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    Esta função imprime e plota a matriz de confusão.\n",
        "    A normalização pode ser aplicada definindo `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Matriz de confusão normalizada\")\n",
        "    else:\n",
        "        print('Matriz de confusão sem normalização')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Label real')\n",
        "    plt.xlabel('Label predito')"
      ],
      "metadata": {
        "id": "kcqtu_G6lP4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acessando os dados que serão entrada do modelo - via Google Drive"
      ],
      "metadata": {
        "id": "PPvowxy_NWlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando a pasta compactada para o notebook\n",
        "folder_path = \"https://drive.usercontent.google.com/download?id=11PLDr83xGsG-lxZMxoFadgEy-iR3q4Qq&export=download&authuser=0&confirm=t&uuid=35044ed5-0d7c-4289-b486-6bf5dea852d0&at=AC2mKKQLNA-0NZzF6s1wgeK530LY:1690032546075\"\n",
        "output = \"scene-classification.zip\"\n",
        "gdown.download(folder_path, output)"
      ],
      "metadata": {
        "id": "rLyI68ZgynXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile('scene-classification.zip', 'r') as zip_object:\n",
        "  zip_object.extractall()"
      ],
      "metadata": {
        "id": "D0BvcUhby9kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/train-scene classification'):\n",
        "  os.rename('../content/train-scene classification','../content/scene')"
      ],
      "metadata": {
        "id": "zMLS6EtKN3C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/scene/train'):\n",
        "  os.rename('../content/scene/train','../content/scene/Imagens')"
      ],
      "metadata": {
        "id": "8C7bL45TOKT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove('../content/scene-classification.zip')"
      ],
      "metadata": {
        "id": "NDDzCnX8YNd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "com_label=pd.read_csv('../content/scene/train.csv',sep=',')\n",
        "sem_label=pd.read_csv('../content/test_WyRytb0.csv',sep=',')"
      ],
      "metadata": {
        "id": "seAs2zxs7iV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "com_label.head()"
      ],
      "metadata": {
        "id": "1pv3Z6R--gm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituindo as categorias numéricas por categorias textuais\n",
        "# (Lembrando que: 0:\"Edificio\", 1:\"Floresta\", 2:\"Geleira\",3:\"Montanha\",4:\"Mar\",5:\"Rua\")\n",
        "com_label['label'] = com_label['label'].replace({0:\"Edificio\", 1:\"Floresta\", 2:\"Geleira\",3:\"Montanha\",4:\"Mar\",5:\"Rua\"})"
      ],
      "metadata": {
        "id": "pE3gmT4uz2kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reavaliando as primeiras linhas para conferir se os valores da coluna label foram alterados\n",
        "com_label.head()"
      ],
      "metadata": {
        "id": "UwxK0zYP0sz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando as dimensões dos DataFrames com as indicações das imagens correspondentes aos conjuntos com label e sem label\n",
        "print(com_label.shape,sem_label.shape)"
      ],
      "metadata": {
        "id": "T7AVE_RypK-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando se os DataFrames contêm dados nulos\n",
        "# Verify if the dataframe don't have NaN or null values\n",
        "check_for_nan_comlabel = com_label.isnull().values.any()\n",
        "check_for_nan_semlabel = sem_label.isnull().values.any()\n",
        "\n",
        "print(check_for_nan_comlabel)\n",
        "print(check_for_nan_semlabel)"
      ],
      "metadata": {
        "id": "avrdjFoL84cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a lista para armazenar os dados e selecionar a pasta da imagem a ser carregada\n",
        "arquivos_com_label = []\n",
        "labels = []\n",
        "arquivos_teste = []\n",
        "arquivos_teste_prediction = []\n",
        "imagePath = \"../content/scene/Imagens/\""
      ],
      "metadata": {
        "id": "ma89bt6e9dam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mantendo na pasta de imagens apenas aquelas que contêm label associado\n",
        "for i in sem_label.index:\n",
        "    nameOfFile = sem_label['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        os.remove(imagePath+nameOfFile)"
      ],
      "metadata": {
        "id": "TTsn_0Ci-vXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=os.listdir(imagePath)\n",
        "\n",
        "heights, widths,filesize = [], [], []\n",
        "\n",
        "# Loop que percorre cada uma das imagens extraídas\n",
        "for fname in images:\n",
        "\n",
        "    img_shape = mpimg.imread(imagePath+fname).shape\n",
        "    heights.append(img_shape[0])\n",
        "    widths.append(img_shape[1])\n",
        "    filesize.append(os.path.getsize(imagePath+fname))\n",
        "\n",
        "# Criação do dataset\n",
        "df = pd.DataFrame({'image_name': images, 'height': heights,\n",
        "                         'width': widths, 'filesize': filesize})\n",
        "print(len(df)) # para confirmação de que apenas as imagens com label (17034) foram mantidas na pasta"
      ],
      "metadata": {
        "id": "BURt0ZKi4V2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "8OcfmIrg5GrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mesclando ao dataframe df a coluna com o label (categoria) das imagens:\n",
        "\n",
        "df=pd.merge(df,com_label,how=\"left\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "F6-8XMcMJlmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.gcf()\n",
        "fig.set_size_inches(3*4, 3*4)\n",
        "\n",
        "# Visualizando 12 imagens\n",
        "for i in range(12):\n",
        "\n",
        "    sample = np.random.choice(images)\n",
        "    for j in range(0,len(df)):\n",
        "      if df['image_name'][j]==sample:\n",
        "        titulo=df['label'][j]\n",
        "        img_path =imagePath+sample\n",
        "        sp = plt.subplot(3, 4, i + 1)\n",
        "        sp.axis('Off')\n",
        "        img = mpimg.imread(img_path)\n",
        "        plt.imshow(img)\n",
        "        plt.title(titulo+\"-\"+df['image_name'][j])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kIoQ6qy4K69q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção II: Passos iniciais para tratamento dos dados"
      ],
      "metadata": {
        "id": "bDK8rZWKyV9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acessando e tratando os dados que serão a entrada do modelo de deep learning"
      ],
      "metadata": {
        "id": "X1RrUXN8xwdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o tamanho do batch e dimensão das imagens e a quantidade de épocas\n",
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150\n",
        "num_classes = 6\n",
        "epochs = 2"
      ],
      "metadata": {
        "id": "X94GKPNHyi22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Associando as imagens ao dataset com label\n",
        "for i in com_label.index:\n",
        "    nameOfFile = com_label['image_name'][i]\n",
        "    if os.path.exists(imagePath+nameOfFile):\n",
        "        image = mpimg.imread(imagePath+nameOfFile)\n",
        "        if (len(image.shape)!=3): # Verify if the image is correct\n",
        "            print(\"A imagem N°\",i,' : ',nameOfFile,\" não está adequada\")\n",
        "        else :\n",
        "            image = cv2.resize(image,(img_width,img_height)) # conjunto de arquivos com label sem imagens \"expúrias\"\n",
        "            arquivos_com_label.append(image)\n",
        "            labels.append(com_label['label'][i])\n",
        "print(len(arquivos_com_label))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "tLjPcA1oGWnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "id": "xkST7JiW2KqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o dataset de treino em array\n",
        "arquivos_com_label = np.array(arquivos_com_label)\n",
        "labels = np.array(labels)\n",
        "print(arquivos_com_label.shape,labels.shape)"
      ],
      "metadata": {
        "id": "QCQV4JfFJc2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção III: Configuração do Modelo de Deep Learning"
      ],
      "metadata": {
        "id": "qcph1B6-9X1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do Modelo usando uma Rede Neural Convolucional (CNN) Simples"
      ],
      "metadata": {
        "id": "z0FWNskh9j9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando a biblioteca Keras, será especificada uma camada convolucional 2D com 32 filtros (depois 64, 128 e 256) e função de ativação do tipo ReLU. Na sequência é adicionada uma camada softmax com o mesmo tipo de função de ativação."
      ],
      "metadata": {
        "id": "00hhPnDH90yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 3, activation='relu', padding= \"same\", input_shape=(img_height,img_width,3)),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(128, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.Conv2D(512, 3, activation='relu', padding= \"same\"),\n",
        "    keras.layers.MaxPooling2D((2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "87lAEFyo-avA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumindo o modelo que será utilizado\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HG_56PeAe-SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinamento do modelo de deep learning"
      ],
      "metadata": {
        "id": "Pk58X8Md-vkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos considerar o modelo Adam para otimização. Como métrica para avaliação do modelo, será usado o critério de acurácia. Além disso, por se tratar de um problema de classificação com mais de 2 categorias (6, neste problema), a perda considerada será do tipo entropia cruzada."
      ],
      "metadata": {
        "id": "fgvpuBNWWn1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fb3pY8mcX0D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação das imagens com labels fornecidos em treino e validação\n",
        "As imagens com categorias fornecidas conforme DataFrame treino serão divididas em treino de fato e validação"
      ],
      "metadata": {
        "id": "59hF9LJkfRC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação do dataset com os labels em treino e teste (20% para teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['image_name'], df['label'], test_size=0.2 ,random_state=42 , shuffle=True)\n",
        "\n",
        "# Redivisão do dataset de treino em treino (90%) e validação (10%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42 , shuffle=True)"
      ],
      "metadata": {
        "id": "TrFB0er1f78c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliando os comprimentos dos datasets de treino e validação\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape)\n",
        "print(X_train.dtype,y_train.dtype,X_test.dtype,y_test.dtype, X_val.dtype,y_val.dtype)"
      ],
      "metadata": {
        "id": "W_23vDe6gXyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirmando que os datasets possuem quantidades representativas de cada uma das seis categorias\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de treino:')\n",
        "print(dict(zip(unique, counts)))\n",
        "print('---------------------------------------------------------------------------')\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de teste:')\n",
        "print(dict(zip(unique, counts)))\n",
        "print('---------------------------------------------------------------------------')\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "print('Distribuição quantitativa dos labels no dataset de validação:')\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "id": "sL2pRIN1435d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a divisão, os datasets de treino, teste e validação ficaram com distribuições significativas e bastante homogêneas de todas as 6 categorias de imagem."
      ],
      "metadata": {
        "id": "KXWjvsn4c0WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando os dataframes correspondentes a X e y teste, treino e validação:\n",
        "dfX_train=pd.DataFrame(X_train)\n",
        "dfX_test=pd.DataFrame(X_test)\n",
        "dfX_val=pd.DataFrame(X_val)\n",
        "\n",
        "dfy_train=pd.DataFrame(y_train)\n",
        "dfy_test=pd.DataFrame(y_test)\n",
        "dfy_val=pd.DataFrame(y_val)"
      ],
      "metadata": {
        "id": "Fq_jLGG6q6Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfX_train.head()"
      ],
      "metadata": {
        "id": "k8H9kARIrBrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfy_train.head()"
      ],
      "metadata": {
        "id": "3Iju0qjVrE1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetando o índice original\n",
        "dfX_train=dfX_train.reset_index()\n",
        "dfX_test=dfX_test.reset_index()\n",
        "dfX_val=dfX_val.reset_index()\n",
        "\n",
        "dfy_train=dfy_train.reset_index()\n",
        "dfy_test=dfy_test.reset_index()\n",
        "dfy_val=dfy_val.reset_index()\n",
        "\n",
        "df_train=pd.merge(dfX_train,dfy_train,how=\"left\")\n",
        "df_test=pd.merge(dfX_test,dfy_test,how=\"left\")\n",
        "df_val=pd.merge(dfX_val,dfy_val,how=\"left\")"
      ],
      "metadata": {
        "id": "0qAzidUUgxcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "yYMngzN-qx0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deletando a coluna index com os índices originais\n",
        "df_train=df_train.drop(columns=[\"index\"])\n",
        "df_test=df_test.drop(columns=[\"index\"])\n",
        "df_val=df_val.drop(columns=[\"index\"])"
      ],
      "metadata": {
        "id": "y8_D7ia8qvRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "-mwZrAOLnnkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(20)"
      ],
      "metadata": {
        "id": "swnZT67mTj9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.head()"
      ],
      "metadata": {
        "id": "obkilJkUTlgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ntrain = X_train.shape[0]\n",
        "nval = X_val.shape[0]\n",
        "ntest = X_test.shape[0]"
      ],
      "metadata": {
        "id": "AKE7vjw6SXjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparação dos dados\n",
        "Será utilizada a classe \"ImageDataGenerator\", do TensorFlow, destinada a aumentar e pré-processar dados de imagem em tarefas de Aprendizado Profundo."
      ],
      "metadata": {
        "id": "lZ4oq9ew0huC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "lEKbxwRYRTeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "    df_train,imagePath,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    x_col='image_name',\n",
        "    y_col='label')\n",
        "\n",
        "val_generator=val_datagen.flow_from_dataframe(\n",
        "    df_val,imagePath,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    x_col='image_name',\n",
        "    y_col='label')\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "    df_test ,imagePath,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    x_col='image_name',\n",
        "    y_col='label')"
      ],
      "metadata": {
        "id": "zWfsYwqdgaK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No presente trabalho, será usado o método flow_from_dataframe() para gerar imagens aumentadas a partir de um dataframe, que aponta para as imagens originais. O método recebe parâmetros como o dataframe, o diretório com as imagens, o tamanho do lote (batch size) e o modo de classe (neste caso, sparse, em função da quantidade de classes), entre outros.\n",
        "\n",
        "Importante ressaltar que o pré-processamento do teste não evolve o aumento de dados."
      ],
      "metadata": {
        "id": "ppTaxdE3duse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, steps_per_epoch=ntrain//batch_size,epochs=epochs)"
      ],
      "metadata": {
        "id": "J01IYgooX5sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção IV: Execução do Modelo de Deep Learning\n",
        "Nesta seção, o modelo treinado será aplicado em cada uma das imagens do dataset de teste, indicando a qual das 6 classes  (Edificio; Floresta; Montanha; Geleira; Rua; Mar) pertence."
      ],
      "metadata": {
        "id": "GcvXwPI1Zkir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parent_dir = imagePath\n",
        "count_images = 0\n",
        "class_names = ['Edificio',\n",
        "               'Floresta',\n",
        "               'Geleira',\n",
        "               'Montanha',\n",
        "               'Mar',\n",
        "               'Rua']\n",
        "y_pred = []\n",
        "y_true = []"
      ],
      "metadata": {
        "id": "enGyUduXlx2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subdir, dirs, files in os.walk(parent_dir):\n",
        "  for file in files:\n",
        "    for i in range(len(df_test)):\n",
        "      if file==df_test['image_name'][i]:\n",
        "        label=df_test['label'][i]\n",
        "        y_true.append(label)\n",
        "        img_path=os.path.join(imagePath,file)\n",
        "        #display(Image(filename=img_path, width=300))\n",
        "\n",
        "        img=image.load_img(img_path, target_size=(img_height, img_width))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = x.astype('float32') / 255.0\n",
        "\n",
        "        # Previsão\n",
        "        prediction = model.predict(x)\n",
        "        # Printando as saídas do modelo\n",
        "        predicted_class = np.argmax(prediction[0])\n",
        "        probability = prediction[0][predicted_class]\n",
        "        y_pred.append(class_names[predicted_class])\n",
        "\n",
        "        display(Image(filename=img_path, width=300))\n",
        "        print(\"Arquivo:\", file)\n",
        "        print(\"Categoria real:\", label)\n",
        "        print(\"Categoria prevista:\", class_names[predicted_class])\n",
        "        print(\"Probabilidade:\", probability)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "5962plU-rp0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seção V: Avaliação do Modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "nqocJPwRZrQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando as métricas para avaliação do modelo\n",
        "acuracia = skm.accuracy_score(y_true, y_pred)\n",
        "precisao = skm.precision_score(y_true, y_pred, average='weighted')\n",
        "recall = skm.recall_score(y_true, y_pred, average='weighted')\n",
        "f1score = skm.f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Acurácia: \", acuracia)\n",
        "print(\"Precisão: \", precisao)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F-Score: \", f1score)"
      ],
      "metadata": {
        "id": "9g7cZ1wSbAgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz de Confusão"
      ],
      "metadata": {
        "id": "ut1mEf41bsQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix = confusion_matrix(y_true, y_pred, labels=class_names)\n",
        "np.set_printoptions(precisao=2)\n",
        "\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      classes=class_names,\n",
        "                      normalize= False,\n",
        "                      title='Matriz real x predição')"
      ],
      "metadata": {
        "id": "LlSvMncocspQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportação do Modelo"
      ],
      "metadata": {
        "id": "Em7aNXdOdTpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos salvar o modelo treinado para aplicação futura\n",
        "\n",
        "# obtendo a data e hora atual\n",
        "now = datetime.now()\n",
        "\n",
        "# Definição do formato\n",
        "format = '%Y-%m-%dT%H%M'\n",
        "\n",
        "# Converter a data e hora em uma string com o formato especificado\n",
        "formatted_datetime = now.strftime(format)\n",
        "\n",
        "path_model = treinamento_modelos_dir\n",
        "\n",
        "name_model = 'trained_model_' + formatted_datetime + '.h5'\n",
        "\n",
        "# salvando o modelo\n",
        "model.save(\"%s/%s\" % (path_model, name_model))\n",
        "print(\"Modelo salvo com o nome: \", name_model)"
      ],
      "metadata": {
        "id": "WrwEB6TOdRgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os caminhos de diretorios para o modelo exportado\n",
        "treinamento_modelos_dir='/content/scene/trained_models'\n",
        "if not os.path.exists(treinamento_modelos_dir):\n",
        "  os.makedirs(treinamento_modelos_dir)"
      ],
      "metadata": {
        "id": "huBaPDnzxiED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}